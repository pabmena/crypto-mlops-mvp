# üöÄ Crypto MLOps MVP

> Infraestructura completa de MLOps para se√±ales de riesgo y volatilidad de criptomonedas con capacidades avanzadas de ML, orquestaci√≥n, APIs modernas y streaming en tiempo real.

## üéØ Trabajo Final - Operaciones de Aprendizaje de M√°quina 2
**üèõÔ∏è Curso de Especializaci√≥n en Inteligencia Artificial**

**Autores:**
- Pablo Ariel Menardi (a1814)  
- Ezequiel Alejandro Caama√±o (a1802)

---

## üìã Resumen Ejecutivo

**Objetivo:** Exponer se√±ales simples de riesgo y volatilidad para criptomonedas (BTC/USDT) a trav√©s de una infraestructura MLOps completa con APIs modernas, streaming en tiempo real y capacidades de ML avanzadas.

**Enfoque:** MVP local sin dependencias de servicios cloud pagos, pero con arquitectura enterprise-ready.

**Aclaraci√≥n Importante:** Los resultados obtenidos con el presente trabajo, no constituyen recomendaci√≥n de operaciones en mercados reales. Su desarrollo tiene SOLO FINES ACAD√âMICOS

## Flujos y tecnolog√≠as

- *Ingesta y orquestaci√≥n*: Airflow ejecuta el DAG crypto_ml_pipeline.py para extraer y procesar OHLCV y (cuando corresponde) reentrenar y desplegar el modelo. Los datos intermedios y artefactos de jobs se manejan como archivos en data/ y via S3 (MinIO). Las ejecuciones quedan registradas en la BD de Airflow (PostgreSQL) configurada en docker-compose.yml.

- *Tracking y artefactos*: MLflow corre con backend en PostgreSQL (MLFLOW_BACKEND_STORE_URI=postgresql://.../mlflow) y almacena artefactos en MinIO (compatible S3) bajo el bucket mlflow. Los scripts scripts/* registran y promueven modelos; la API los carga desde MLflow en producci√≥n.

- *Serving y UI*: La API FastAPI (api/app.py) expone endpoints para se√±ales heur√≠sticas y predicciones ML, y una UI integrada que consume esos endpoints. La API lee el modelo de MLflow en startup, y persiste hist√≥ricos ligeros en archivos JSONL (api/data/*) para la vista de ‚ÄúHistory‚Äù.

- *Streaming en tiempo real (Kafka)*: El producer publica ticks de precios en el t√≥pico crypto-prices (reales v√≠a CCXT o simulados). El consumer lee ese stream, calcula indicadores, genera se√±al heur√≠stica, consulta la API para predicci√≥n ML y publica resultados en predictions y alertas en alerts. Estos servicios demuestran el pipeline streaming y su integraci√≥n con la API de ML; no est√°n conectados directamente a la UI por simplicidad, pero podr√≠an integrarse f√°cilmente exponiendo en FastAPI un WebSocket/Server-Sent Events que consuma predictions o agregando un endpoint que lea del stream/cache para que la UI lo consulte.

- *Bases de datos usadas*:
  - *PostgreSQL*: backend de MLflow (runs/metrics/params) y base de Airflow.
  - *MinIO (S3)*: almacenamiento de artefactos de MLflow (modelos, scalers, etc.).
  - Archivos locales JSONL para historiales simples de se√±ales/predicciones en la API.
 
En conjunto, Airflow coordina los workflows batch, MLFlow versiona y sirve modelos con artefactos en MinIO, FastApi sirve predicciones y la UI, y Kafka muestra la variante streaming de ingesta y scoring en tiempo real, con la opci√≥n de conectarla a la UI via FastApi si se quiere visualizaci√≥n live.

## üèóÔ∏è Arquitectura del Sistema

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        CRYPTO MLOPS ARCHITECTURE                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Client Layer                                                        ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ ‚îÇ REST API    ‚îÇ GraphQL     ‚îÇ gRPC        ‚îÇ Web Dashboards      ‚îÇ   ‚îÇ
‚îÇ ‚îÇ :8800/docs  ‚îÇ :4000/gql   ‚îÇ :50051      ‚îÇ Multiple UIs        ‚îÇ   ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ Processing Layer                                                    ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ ‚îÇ FastAPI     ‚îÇ ML Service  ‚îÇ Streaming   ‚îÇ Airflow             ‚îÇ   ‚îÇ
‚îÇ ‚îÇ (Main API)  ‚îÇ (LSTM)      ‚îÇ (Kafka)     ‚îÇ (Pipelines)         ‚îÇ   ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ Data & ML Layer                                                     ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ ‚îÇ MLFlow      ‚îÇ MinIO       ‚îÇ PostgreSQL  ‚îÇ Kafka Topics        ‚îÇ   ‚îÇ
‚îÇ ‚îÇ :5000/ui    ‚îÇ :9001/ui    ‚îÇ (DB)        ‚îÇ (prices/alerts)     ‚îÇ   ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## ‚ú® Caracter√≠sticas Principales

- **ü§ñ Machine Learning:** Modelo LSTM bidireccional para predicci√≥n de volatilidad
- **üìä MLFlow:** Tracking completo de experimentos y model registry
- **üîÑ Orquestaci√≥n:** Pipelines automatizados con Airflow + MinIO
- **üåê APIs Modernas:** REST, GraphQL y gRPC para m√°xima flexibilidad
- **üì° Streaming:** Kafka para datos en tiempo real
- **üìà Dashboards:** Interfaces web para monitoreo y an√°lisis
- **üê≥ Docker:** Todo containerizado y production-ready

---

## üõ†Ô∏è Prerrequisitos

**Sistema Operativo:** Linux, macOS, o Windows con WSL2

**Requisitos:**
- Docker Desktop con **m√≠nimo 8GB RAM** disponibles
- Git
- **10GB+** de espacio libre en disco
- Puertos disponibles: 8800, 5000, 8080, 9001, 4000, 8088, 50051, 9092

---

## üöÄ Instalaci√≥n R√°pida

### Opci√≥n 1: Setup Automatizado (Recomendado)

```bash
# 1. Clonar repositorio
git clone https://github.com/pabmena/crypto-mlops-mvp.git
cd crypto-mlops-mvp

# 2. Cambiar a la branch correcta
git checkout feature/mlflow-implementation

# 3. Ejecutar setup completo
chmod +x scripts/setup.sh
./scripts/setup.sh
```

### Opci√≥n 2: Setup Manual

```bash
# 1. Crear archivos de configuraci√≥n
cp .env.example .env

# 2. Levantar servicios
docker-compose up -d --build

# 3. Esperar inicializaci√≥n (2-3 minutos)
make check-health

# 4. Configurar buckets de MinIO
make setup-buckets

# 5. Entrenar modelo inicial (opcional)
make train-model
```

### Opci√≥n 3: Usando Make

```bash
# Todo en un comando
make setup
```

---

## üåê Servicios Disponibles

Una vez iniciado el sistema, tendr√°s acceso a:

| Servicio | URL | Credenciales | Descripci√≥n |
|----------|-----|--------------|-------------|
| **FastAPI** | [http://localhost:8800/docs](http://localhost:8800/docs) | - | API principal con Swagger UI |
| **MLFlow** | [http://localhost:5000](http://localhost:5000) | - | Experimentos ML y model registry |
| **Airflow** | [http://localhost:8080](http://localhost:8080) | `admin/admin` | Orquestaci√≥n de pipelines |
| **MinIO** | [http://localhost:9001](http://localhost:9001) | `minioadmin/minioadmin123` | Object storage UI |
| **GraphQL** | [http://localhost:4000/graphql](http://localhost:4000/graphql) | - | Playground GraphQL |
| **Kafka UI** | [http://localhost:8088](http://localhost:8088) | - | Monitoreo de topics Kafka |

---

## üß™ Testing y Verificaci√≥n

### Verificar Estado del Sistema

```bash
# Estado de todos los servicios
make check-health

# URLs de todos los dashboards
make dashboard-urls

# Monitoreo en tiempo real
make monitor
```

### Tests de API REST

```bash
# Se√±al heur√≠stica b√°sica
curl -X POST "http://localhost:8800/v1/crypto/signal" \
  -H "Content-Type: application/json" \
  -d '{"symbol":"BTCUSDT","explain":true}'

# Predicci√≥n con ML
curl -X POST "http://localhost:8800/v1/crypto/ml-signal" \
  -H "Content-Type: application/json" \
  -d '{"symbol":"BTCUSDT","include_heuristic":true}'

# Comparaci√≥n de m√©todos
curl "http://localhost:8800/v1/crypto/signals/compare?symbol=BTCUSDT"
```

### Test GraphQL

```graphql
query {
  health {
    status
    mlAvailable
  }
  modelInfo {
    modelLoaded
    modelVersion
  }
}
```

### Tests Automatizados

```bash
# Ejecutar suite completa de tests
make test-apis

# Generar datos de prueba
make generate-test-data

# Tests unitarios
make test
```

---

## üìä Machine Learning

### Modelo LSTM

**Arquitectura:** LSTM bidireccional para predicci√≥n de volatilidad  
**Features:** Precio, volumen, RSI, SMA, Bollinger Bands  
**Target:** Volatilidad futura (24h)  
**Framework:** TensorFlow/Keras

### Gesti√≥n del Modelo

```bash
# Entrenar modelo desde cero
make train-model

# Ver experimentos en MLFlow
open http://localhost:5000

# Recargar modelo en producci√≥n
curl -X POST http://localhost:8800/v1/ml/model/reload
```

### Endpoints ML

| Endpoint | M√©todo | Descripci√≥n |
|----------|---------|------------|
| `/v1/ml/model/info` | GET | Informaci√≥n del modelo actual |
| `/v1/ml/model/reload` | POST | Recargar modelo desde MLFlow |
| `/v1/crypto/ml-signal` | POST | Generar predicci√≥n ML |
| `/v1/crypto/signals/compare` | GET | Comparar m√©todos heur√≠stico vs ML |

---

## üîÑ Orquestaci√≥n con Airflow

### DAG Principal: `crypto_ml_pipeline`

**Tareas:**
1. Extracci√≥n de datos crypto
2. Procesamiento y feature engineering  
3. Validaci√≥n de calidad de datos
4. Reentrenamiento de modelo
5. Deploy autom√°tico a producci√≥n

### Gesti√≥n de Pipelines

```bash
# Acceder a Airflow UI
open http://localhost:8080

# Ver logs de Airflow
make logs-airflow

# Triggear pipeline manualmente desde UI o:
# En Airflow UI -> DAGs -> crypto_ml_pipeline -> Trigger DAG
```

---

## üì° Streaming con Kafka

### Topics Disponibles

- **crypto-prices:** Precios en tiempo real
- **predictions:** Predicciones generadas  
- **alerts:** Alertas de anomal√≠as

### Monitoreo de Streaming

```bash
# Ver topics activos
make show-kafka-topics

# Logs del streaming
make logs-kafka

# UI de Kafka
open http://localhost:8088
```

### Ejemplo de Mensaje

```json
{
  "symbol": "BTCUSDT",
  "price": 43250.00,
  "volume": 1234.56,
  "timestamp": "2025-08-21T10:30:00Z",
  "volatility_prediction": 0.0234
}
```

---

## üíæ Gesti√≥n de Datos con MinIO

### Buckets Autom√°ticos

- **raw-data:** Datos crudos de exchanges
- **processed-data:** Features procesadas
- **models:** Modelos ML entrenados
- **mlflow:** Artefactos de MLFlow
- **quality-reports:** Reportes de calidad

### Comandos √ötiles

```bash
# Acceder a MinIO UI
open http://localhost:9001

# CLI dentro del container
docker-compose exec minio mc ls local/

# Backup de datos
make backup-data
```

---

## üîå APIs Disponibles

### REST API (FastAPI)

**Base URL:** `http://localhost:8800`

#### Endpoints Principales

```bash
GET    /health              # Health check
GET    /metrics             # M√©tricas del sistema  
GET    /v1/crypto/ohlcv     # Datos OHLCV
POST   /v1/crypto/signal    # Se√±al heur√≠stica
POST   /v1/crypto/ml-signal # Predicci√≥n ML
GET    /v1/crypto/signals/compare # Comparar m√©todos
```

### GraphQL API

**URL:** `http://localhost:4000/graphql`

#### Queries Disponibles

- `health()`: Estado del sistema
- `modelInfo()`: Informaci√≥n del modelo ML  
- `ohlcvData(input)`: Datos hist√≥ricos

#### Mutations Disponibles

- `generateSignal(input)`: Generar se√±al heur√≠stica
- `generateMlSignal(input)`: Generar predicci√≥n ML

### gRPC API

**Puerto:** `50051`

#### Servicios Disponibles

- `GetOHLCV`: Obtener datos hist√≥ricos
- `GenerateSignal`: Generar se√±al heur√≠stica  
- `GenerateMLPrediction`: Predicci√≥n ML
- `CompareSignals`: Comparar m√©todos
- `HealthCheck`: Verificar estado
- `StreamPrices`: Stream de precios en tiempo real

---

## üìà Monitoreo y M√©tricas

### M√©tricas del Sistema

```bash
# Ver m√©tricas en tiempo real
curl http://localhost:8800/metrics
```

### Ejemplo de Respuesta

```json
{
  "start_time": "2025-08-21T10:00:00Z",
  "requests_total": 1542,
  "signals_total": 234, 
  "ml_predictions_total": 89,
  "last_signal_at": "2025-08-21T10:30:00Z",
  "last_ml_prediction_at": "2025-08-21T10:25:00Z"
}
```

### Comandos de Monitoreo

```bash
# Monitoreo interactivo
make monitor

# Logs por servicio
make logs-api      # Solo API
make logs-mlflow   # Solo MLFlow  
make logs-kafka    # Solo Kafka
make logs-airflow  # Solo Airflow

# Todos los logs
make logs
```

---

## üõ†Ô∏è Comandos Make Disponibles

### Setup y Configuraci√≥n
```bash
make setup          # Setup completo autom√°tico
make check-health    # Verificar estado de servicios  
make setup-buckets   # Configurar buckets de MinIO
```

### Desarrollo y Testing  
```bash
make test           # Tests unitarios
make test-apis      # Tests de endpoints
make train-model    # Entrenar modelo ML
make generate-test-data # Generar datos de prueba
```

### Monitoreo y Logs
```bash
make monitor        # Monitoreo en tiempo real
make dashboard-urls # URLs de dashboards
make logs          # Ver todos los logs
make logs-api      # Logs espec√≠ficos del API
```

### Mantenimiento
```bash
make clean         # Limpiar recursos Docker
make backup-data   # Backup de datos
make dev-reset     # Reset completo del entorno
```

### Kafka y Streaming
```bash
make show-kafka-topics # Ver topics de Kafka
make logs-kafka       # Logs del streaming
```

---

## ‚öôÔ∏è Configuraci√≥n

### Variables de Entorno (.env)

```bash
# Database
POSTGRES_USER=mlops
POSTGRES_PASSWORD=mlops123
POSTGRES_DB=crypto_mlops

# MLFlow  
MLFLOW_TRACKING_URI=http://localhost:5000
MLFLOW_BACKEND_STORE_URI=postgresql://mlops:mlops123@postgres:5432/crypto_mlops

# MinIO
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin123

# Kafka
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
KAFKA_AUTO_CREATE_TOPICS_ENABLE=true

# API Keys (opcional para datos reales)
BINANCE_API_KEY=your_api_key
BINANCE_SECRET_KEY=your_secret_key
```

---

## üêõ Troubleshooting

### Problemas Comunes

#### Servicios no responden
```bash
make check-health
docker-compose restart api
```

#### Falta de memoria
```bash
docker system prune -f
make clean
```

#### Puerto ocupado
```bash
# Verificar qu√© proceso usa el puerto
sudo netstat -tlnp | grep :8800

# Liberar puerto si es necesario
sudo kill -9 <PID>
```

#### MLFlow no conecta
```bash
make logs-mlflow
docker-compose restart mlflow postgres
```

#### Kafka no produce/consume  
```bash
make logs-kafka
docker-compose restart kafka zookeeper
```

### Logs Detallados

```bash
# Ver todos los logs
make logs

# Logs espec√≠ficos por servicio  
docker-compose logs -f api
docker-compose logs -f mlflow
docker-compose logs -f airflow-webserver
docker-compose logs -f crypto-producer
```

### Reset Completo

```bash
# Si nada funciona, reset completo
make dev-reset
```

---

## üè≠ Consideraciones para Producci√≥n

### Seguridad

- **Cambiar credenciales por defecto** en `.env`
- **Configurar HTTPS/TLS** para todos los servicios
- **Implementar autenticaci√≥n** y autorizaci√≥n
- **Configurar firewall** y network policies

### Escalabilidad

- **Migrar a Kubernetes** en lugar de Docker Compose
- **Configurar auto-scaling** para componentes cr√≠ticos
- **Implementar load balancers**
- **Usar base de datos gestionada**

### Monitoreo

- **Integrar con Prometheus/Grafana**
- **Configurar alertas** proactivas
- **Logging centralizado** con ELK Stack
- **APM** para performance monitoring

### Backup y Recuperaci√≥n

- **Backup autom√°tico** de datos cr√≠ticos
- **Disaster recovery plan**
- **Testing de backups** regular

---

## üìÅ Estructura del Proyecto

```
crypto-mlops-mvp/
‚îú‚îÄ‚îÄ api/                    # FastAPI application
‚îÇ   ‚îú‚îÄ‚îÄ models/            # Pydantic models
‚îÇ   ‚îú‚îÄ‚îÄ routes/            # API routes  
‚îÇ   ‚îî‚îÄ‚îÄ services/          # Business logic
‚îú‚îÄ‚îÄ ml/                     # ML models and services
‚îÇ   ‚îú‚îÄ‚îÄ models/            # Model definitions
‚îÇ   ‚îú‚îÄ‚îÄ inference/         # Inference service
‚îÇ   ‚îú‚îÄ‚îÄ training/          # Training scripts
‚îÇ   ‚îî‚îÄ‚îÄ mlflow/            # MLFlow configuration
‚îú‚îÄ‚îÄ airflow/               # Airflow DAGs
‚îÇ   ‚îú‚îÄ‚îÄ dags/             # DAG definitions
‚îÇ   ‚îî‚îÄ‚îÄ plugins/          # Custom plugins
‚îú‚îÄ‚îÄ streaming/             # Kafka producer/consumer
‚îÇ   ‚îú‚îÄ‚îÄ producer/         # Data producers
‚îÇ   ‚îî‚îÄ‚îÄ consumer/         # Data consumers
‚îú‚îÄ‚îÄ grpc/                  # gRPC server
‚îú‚îÄ‚îÄ graphql/               # GraphQL server  
‚îú‚îÄ‚îÄ scripts/               # Setup and utility scripts
‚îú‚îÄ‚îÄ data/                  # Persistent data
‚îú‚îÄ‚îÄ docker-compose.yml     # Services orchestration
‚îú‚îÄ‚îÄ .env.example          # Environment variables template
‚îú‚îÄ‚îÄ Makefile              # Automation commands
‚îî‚îÄ‚îÄ README.md             # This file
```

---

## ü§ù Contribuir

1. **Fork** del proyecto
2. Crear **feature branch**: `git checkout -b feature/nueva-funcionalidad`  
3. **Commit** cambios: `git commit -am 'Agregar nueva funcionalidad'`
4. **Push** a la branch: `git push origin feature/nueva-funcionalidad`
5. Crear **Pull Request**

---

## üìù Licencia

MIT License - Ver [LICENSE](LICENSE) para m√°s detalles.

---

## üìû Soporte

Para reportar bugs o solicitar features:
- **Issues:** [GitHub Issues](https://github.com/pabmena/crypto-mlops-mvp/issues)
- **Documentaci√≥n:** Este README
- **Contacto:** Pablo Menardi & Ezequiel Caama√±o

---

## üôè Agradecimientos

Proyecto desarrollado como Trabajo Final para la materia **Operaciones de Aprendizaje de M√°quina 2** del **Curso de Especializaci√≥n en Inteligencia Artificial**.

**Universidad:** Universidad de Buenos Aires  
**A√±o:** 2025

---

> üí° **Tip:** Para una experiencia √≥ptima, inicia con `make setup` y luego accede a http://localhost:8800/docs para explorar la API interactiva.
